{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b409c40-87e9-4c2b-97e9-c7db9663cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b8f0a71-dccb-46e3-bb10-76d1b9a37aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (7291, 256)\n",
      "Labels shape: (7291,)\n"
     ]
    }
   ],
   "source": [
    "# Path to the ZipDigits.train file\n",
    "file_path = 'ZipDigits.train'\n",
    "\n",
    "# Load the data from the file\n",
    "data = []\n",
    "\n",
    "# Read the file line by line\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        values = list(map(float, line.split()))  # Convert each line to a list of floats\n",
    "        data.append(values)\n",
    "\n",
    "# Convert the list to a NumPy array for easier manipulation\n",
    "data = np.array(data)\n",
    "\n",
    "# Split the data into labels (first column) and features (remaining columns)\n",
    "labels = data[:, 0]      # Labels are the first column\n",
    "features = data[:, 1:]   # Features are the remaining columns\n",
    "\n",
    "# Display the shape of features and labels\n",
    "print(f'Features shape: {features.shape}')\n",
    "print(f'Labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3198165-7647-4bd4-bfd2-af75b2e1d25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5832, 256)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36e46438-881b-4da5-91e5-b661723c2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relevant_data(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Filters the dataset to keep only the samples corresponding to the digits 1 and 5.\n",
    "\n",
    "    :param X_train: Training data (numpy array of shape (n_samples_train, n_features))\n",
    "    :param y_train: Training labels (numpy array of shape (n_samples_train,))\n",
    "    :param X_test: Test data (numpy array of shape (n_samples_test, n_features))\n",
    "    :param y_test: Test labels (numpy array of shape (n_samples_test,))\n",
    "    :return: X_train_f, y_train_f, X_test_f, y_test_f: Filtered training and test sets\n",
    "             containing only samples where the labels are 1 or 5.\n",
    "    \"\"\"\n",
    "    # Filter the training data for labels 1 and 5\n",
    "    train_filter = np.isin(y_train, [1, 5])\n",
    "    X_train_f = X_train[train_filter]\n",
    "    y_train_f = y_train[train_filter]\n",
    "\n",
    "    # Filter the test data for labels 1 and 5\n",
    "    test_filter = np.isin(y_test, [1, 5])\n",
    "    X_test_f = X_test[test_filter]\n",
    "    y_test_f = y_test[test_filter]\n",
    "\n",
    "    # Return the filtered data\n",
    "    return X_train_f, y_train_f, X_test_f, y_test_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb5677bc-93a7-436e-b0a1-d9470ca8f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f,y_train_f,X_test_f,y_test_f=filter_relevant_data(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d90031d0-ecd4-43cf-add4-581fc08dd83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1233, 256)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd1fb920-1e97-45aa-80a4-4e6f232289c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate vertical symmetry\n",
    "def vertical_symmetry(image):\n",
    "    left_half = image[:, :8]  # Left half (first 8 columns)\n",
    "    right_half = np.fliplr(image[:, 8:])  # Right half, flipped horizontally\n",
    "    symmetry = np.mean(np.abs(left_half - right_half))  # Mean absolute difference\n",
    "    return symmetry\n",
    "\n",
    "# Function to calculate horizontal symmetry\n",
    "def horizontal_symmetry(image):\n",
    "    top_half = image[:8, :]  # Top half (first 8 rows)\n",
    "    bottom_half = np.flipud(image[8:, :])  # Bottom half, flipped vertically\n",
    "    symmetry = np.mean(np.abs(top_half - bottom_half))  # Mean absolute difference\n",
    "    return symmetry\n",
    "\n",
    "# Function to calculate the width (using a threshold to determine pixel activation)\n",
    "def width(image, threshold=0.5):\n",
    "    # Count non-zero pixels (greater than threshold) along the columns\n",
    "    width = np.sum(np.max(image > threshold, axis=0))\n",
    "    return width\n",
    "\n",
    "def intensity(image):\n",
    "    return np.mean(X_train)\n",
    "\n",
    "# Main function to apply feature transform\n",
    "def feature_transform(X,func1,func2):\n",
    "    \"\"\"\n",
    "    Applies feature transformations to each image in X and returns a 1D numpy array\n",
    "    with a single feature value per image.\n",
    "    \n",
    "    :param X: numpy array of shape (n_samples, 256), where each row is a flattened 16x16 image\n",
    "    :return: numpy array of shape (n_samples,) containing one feature value per image\n",
    "    \"\"\"\n",
    "    # Initialize list to store the transformed features\n",
    "    transformed_features = []\n",
    "\n",
    "    # Loop over each image (flattened) in X\n",
    "    for i in range(X.shape[0]):\n",
    "        image = X[i].reshape(16, 16)  # Reshape the 256 feature vector to 16x16\n",
    "        \n",
    "        # Calculate the feature transform\n",
    "        #vertical_symmetry = calculate_vertical_symmetry(image)\n",
    "        #horizontal_symmetry = calculate_horizontal_symmetry(image)\n",
    "        #width = calculate_width(image)\n",
    "        \n",
    "        # For simplicity, let's combine these features (you can choose how to combine them)\n",
    "        # For this example, we'll just use the width as the feature, but you can customize this\n",
    "        #feature_value = func(image)\n",
    "        \n",
    "        # Append the calculated feature to the list\n",
    "        features=[func1(image),func2(image)]\n",
    "        transformed_features.append(features)\n",
    "\n",
    "    # Convert the list to a numpy array and return\n",
    "    return np.array(transformed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef06d05c-9c84-49f0-b39d-417da7c48c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new=feature_transform(X_train_f,horizontal_symmetry,intensity)\n",
    "X_test_new=feature_transform(X_test_f,horizontal_symmetry,intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33392c2d-899a-4309-9cf3-1df51062d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_transform(X_train_transformed):\n",
    "    \"\"\"\n",
    "    Applies a set of nonlinear transformations to the input array X_train_transformed.\n",
    "\n",
    "    :param X_train_transformed: numpy array of shape (n_samples, 2), \n",
    "                                where each row represents a pair of features.\n",
    "    :return: X_train_nonlin: numpy array with the nonlinear transformations applied.\n",
    "    \"\"\"\n",
    "    # Extract the two columns/features from X_train_transformed\n",
    "    x1 = X_train_transformed[:, 0]  # First feature\n",
    "    x2 = X_train_transformed[:, 1]  # Second feature\n",
    "\n",
    "    # Apply nonlinear transformations\n",
    "    x1_squared = np.square(x1)         # x1^2\n",
    "    x2_squared = np.square(x2)         # x2^2\n",
    "    x1_cubed = np.power(x1, 3)         # x1^3\n",
    "    x2_cubed = np.power(x2, 3)         # x2^3\n",
    "    x1_exp = np.exp(x1)                # exp(x1)\n",
    "    x2_exp = np.exp(x2)                # exp(x2)\n",
    "    x1_sin = x1+x2_squared                # x1+x2^2\n",
    "    x2_sin = x2+x1_squared                # x2+x1^2\n",
    "    x1x2=x1*x2\n",
    "    x12_x23=x1_squared+x2_cubed\n",
    "\n",
    "    # Combine all transformations into a new feature matrix\n",
    "    X_train_nonlin = np.column_stack((x1, x2, x1_squared, x2_squared, x1_cubed, x2_cubed, x1_exp, x2_exp, x1_sin, x2_sin,x1x2,x12_x23))\n",
    "\n",
    "    # Return the transformed array\n",
    "    return X_train_nonlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbaa552-c22b-44c8-b404-3d1ecc68186c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "867c1456-996e-4e2c-a427-e4493bbeba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans=nonlinear_transform(X_train_new)\n",
    "X_test_trans=nonlinear_transform(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d49bb66-c189-4d8f-ace3-df931c9f56d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 99.70%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def svm_fit_and_test(X_train_transformed, y_train, X_test_transformed, y_test,C=1):\n",
    "    \"\"\"\n",
    "    Trains an SVM on the nonlinear transformed training data and tests its accuracy.\n",
    "    \n",
    "    :param X_train_transformed: Transformed training data (numpy array)\n",
    "    :param y_train: Training labels (numpy array)\n",
    "    :param X_test_transformed: Transformed test data (numpy array)\n",
    "    :param y_test: Test labels (numpy array)\n",
    "    :return: accuracy: The accuracy of the SVM on the test data.\n",
    "    \"\"\"\n",
    "    # Apply nonlinear transform to both train and test data\n",
    "    X_train_nonlin = nonlinear_transform(X_train_transformed)\n",
    "    X_test_nonlin = nonlinear_transform(X_test_transformed)\n",
    "    \n",
    "    # Initialize the SVM classifier\n",
    "    svm_model = SVC(kernel='rbf',C=C)  # RBF kernel (default), can use others like 'linear', 'poly', 'sigmoid'\n",
    "    \n",
    "    # Fit the SVM model on the training data\n",
    "    svm_model.fit(X_train_nonlin, y_train)\n",
    "    \n",
    "    # Predict the labels on the test set\n",
    "    y_pred = svm_model.predict(X_test_nonlin)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return accuracy\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X_train_transformed and X_test_transformed are (5500, 2) and (500, 2)\n",
    "# Assuming y_train and y_test are the labels for the training and test sets\n",
    "\n",
    "# Fit SVM and get accuracy\n",
    "accuracy = svm_fit_and_test(X_train_trans, y_train_f, X_test_trans, y_test_f)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"SVM Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1ebc30a-dd93-40c8-945a-2ec86bcf3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit_image(index):\n",
    "    \"\"\"\n",
    "    Plots the digit image at a given index from the features and labels.\n",
    "    \n",
    "    :param index: The index of the digit to plot (0 to len(features)-1)\n",
    "    \"\"\"\n",
    "    # Reshape the features into a 16x16 image\n",
    "    image = features[index].reshape(16, 16)\n",
    "    \n",
    "    # Get the corresponding label\n",
    "    label = int(labels[index])\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bac927e-ae04-48c6-8fd3-3a92948bdb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit_image(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a81263-8df0-4c67-a7ba-91e01dcc6c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
